hydra:
  run:
    dir: outputs

model_type: hf
name: mistral-7b-instruct-v02-hf

model_config:
  pretrained_model_name_or_path: mistralai/Mistral-7B-Instruct-v0.2
  model_id: # unique identifier for accessing conversation buffer
  load_in_8bit: false
  device_map: auto
  torch_dtype: float16
  model_cache_dir: /scr/jphilipp/printllama-hgx/pretrained_models/
  tokenizer_cache_dir: /scr/jphilipp/prinllama-hfx/pretrained_models/
  seed: 1

run:
  batch_size: 1
  verbose: false
  completion_config:
    do_sample: true
    temperature: 0.7
    top_p: 0.9
    max_new_tokens: 300
    num_return_sequences: 50
